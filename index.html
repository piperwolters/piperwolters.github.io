<!doctype html>
<html>

<head>
    <title>Piper Wolters</title>
    <style>
        body {
            display: flex;
            justify-content: center;
            align-items: center;
            margin: 0;
            padding: 20px;
        }

        .container {
	    width: 75%;
            max-width: 750px;;
            text-align: left;
        }

        a {
            text-decoration: none;
        }

    	.container p {
            font-size: 0.95rem; 
    	}

        img {
            float: right;
            width: 275px;
            height: 275px;
	    margin-left: 20px;
        }

        .centered-title {
            text-align: center;
	    font-weight: normal;
	    font-size: 2rem;
        }

	.research-title {
	    //font-size: 1.60rem;
	    font-weight: normal;
            margin-top: 70px;
	}

	.centered-links {
	    text-align: center;
	    margin: 20px 0;
	}

	/* Media query for smaller screens */
	@media (max-width: 600px) {
	    .research-title {
		font-size: 2.0rem;
	    }
	}

    </style>
</head>

<body>
    <div class="container">
        <img src="images/piperw.jpg" alt="Photo of Piper">
        <h1 class="centered-title">Piper Wolters</h1>
        <p>piperw@allenai.org</p>

        <p>
            I am a Research Engineer at <a href="https://prior.allenai.org/">PRIOR</a>, the Computer Vision team at the <a href="https://allenai.org/">Allen Institute for Artificial Intelligence</a>, where I have had the pleasure of collaborating with <a href="https://tanmaygupta.info/">Tanmay Gupta</a>, <a href="https://anikem.github.io/">Ani Kembhavi</a>, and <a href="https://favyen.com/">Favyen Bastani</a>.
            I received my B.S. and M.S. degrees in Computer Science at Western Washington University,
            where I was advised by <a href="https://facultyweb.cs.wwu.edu/~hutchib2/">Brian Hutchinson</a>.
        </p>

	<div class="centered-links">
	    <a href="https://github.com/piperwolters">Github</a> / 
	    <a href="https://scholar.google.com/citations?hl=en&user=8fvuCcMAAAAJ">Google Scholar</a> / 
	    <a href="https://www.linkedin.com/in/piper-wolters/">Linkedin</a>
	</div>

        <h2 class="research-title">Research</h2>

	<i>I enjoy employing AI to tackle important problems and ensuring that all of my work is openly available.</i>

        <p><b>OPTIMUS: Observing Persistent Transformations in Multi-temporal Unlabeled Satellite-data</b><br>
            Paul Seulchan Han, Raymond Yu, Josh Myers-Dean, <i>Piper Wolters</i>, Favyen Bastani. <br>
            WACV 2025. <br>
	    <a href="https://openaccess.thecvf.com//content/WACV2025/papers/Yu_OPTIMUS_Observing_Persistent_Transformations_in_Multi-Temporal_Unlabeled_Satellite-Data_WACV_2025_paper.pdf">[paper]</a>
	</p>

        <p><b>Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models</b><br>
            Matt Deitke, Christopher Clark, ..., <i>Piper Wolters</i>, et. al.<br>
            2024. <br>
            <a href="https://molmo.allenai.org/blog">[blog]</a>
            <a href="https://molmo.allenai.org/">[demo]</a>
            <a href="https://arxiv.org/abs/2409.17146">[paper]</a></p>

        <p><b>On the Generalizability of Foundation Models for Crop Type Mapping</b><br>
            Yi-Chia Chang, Adam J Stewart, Favyen Bastani, <i>Piper Wolters</i>, et. al.<br>
            2024. <br>
            <a href="https://arxiv.org/abs/2409.09451">[arxiv]</a></p>

        <p><b>Zooming Out on Zooming In: Advancing Super-Resolution for Remote Sensing.</b><br>
            <i>Piper Wolters</i>, Favyen Bastani, Aniruddha Kembhavi. <br>
            2023. <br>
            <a href="https://arxiv.org/pdf/2311.18082.pdf">[arxiv]</a>
            <a href="https://github.com/allenai/satlas-super-resolution">[code]</a>
            <a href="https://satlas.allen.ai/superres">[website]</a></p>

        <p><b>Satellite Imagery and AI: A New Era in Ocean Conservation, from Research to Deployment and Impact.</b><br>
            Patrick Beukema, Favyen Bastani, <i>Piper Wolters</i>, Henry Herzog, Joseph George Ferdinando.<br>
            NeurIPS CompSust 2023. Best Paper Award.<br>
            <a href="https://arxiv.org/pdf/2312.03207.pdf">[arxiv]</a></p>

        <p><b>Satlas: Creating Accurate, Global Geospatial Data Products with Large-scale Pre-training.</b><br>
            Favyen Bastani, <i>Piper Wolters</i>, Aniruddha Kembhavi.<br>
            AGU Fall Meeting Abstracts 2023. <br>
            <a href="https://ui.adsabs.harvard.edu/abs/2023AGUFMGC21F0984B/abstract">[abstract]</a>
            <a href="https://satlas.allen.ai">[website]</a></p>

        <p><b>SatlasPretrain: A Large-Scale, Multi-Task Dataset for Remote Sensing Image Understanding.</b><br>
            Favyen Bastani, <i>Piper Wolters</i>, Ritwik Gupta, Joe Ferdinando, Aniruddha Kembhavi.<br>
            ICCV 2023.<br>
            <a href="https://arxiv.org/abs/2211.15660">[arxiv]</a></p>

        <p><b>Automatic Deep-Learning-Based Classification of Bottlenose Dolphin Signature Whistles.</b><br>
            Frants Jensen, <i>Piper Wolters</i>, et. al.<br>
            International Conference on the Effects of Noise on Aquatic Life 2022.<br>
            <a href="https://github.com/AllenMLI/dolphin_signature_whistles">[code]</a>
            <a href="https://dolphin-whistles.apps.allenai.org">[gui]</a>
            <a href="https://link.springer.com/referenceworkentry/10.1007/978-3-031-10417-6_143-1">[pdf]</a></p>

        <p><b>Vessel Detection in Sentinel-1 Imagery.</b><br>
            Favyen Bastani, <i>Piper Wolters</i>, Rose Hendrix, Joseph Ferdinando, Aniruddha Kembhavi.<br>
            xView3 Competition 2022. US 1st Place.<br>
            <a href="https://github.com/allenai/sar_vessel_detect">[code]</a>
            <a href="https://github.com/allenai/sar_vessel_detect/blob/main/whitepaper.pdf">[pdf]</a></p>

        <p><b>Conditional Emulation of Global Precipitation with Generative Adversarial Networks.</b><br>
            Alex Ayala, Chris Drazic, Seth Bassetti, Eric Slyman, Brenna Nieva, <i>Piper Wolters</i>, et. al.<br>
            ICLR AI4EarthScience Workshop 2022.<br>
            <a href="https://ai4earthscience.github.io/iclr-2022-workshop/camera_ready/iclr_2022_ai4ess_30.pdf">[pdf]</a></p>

        <p><b>Proposal-based Few-Shot Sound Event Detection for Speech and Environmental Sounds with Perceivers.</b><br>
            <i>Piper Wolters</i>, Chris Daw, Brian Hutchinson, Lauren Phillips. <br>
            2021. <br>
            <a href="https://arxiv.org/abs/2107.13616">[arxiv]</a></p>

        <p><b>A Study of Few-Shot Audio Classification.</b><br>
            <i>Piper Wolters</i>, Chris Careaga, Brian Hutchinson, Lauren Phillips.<br>
            Grace Hopper Celebration of Women in Computing 2020.<br>
            <a href="https://arxiv.org/abs/2012.01573">[arxiv]</a>
            <a href="https://vghc-anitab.ipostersessions.com/default.aspx?s=C3-17-70-FA-9B-C6-B0-1D-A0-A4-34-63-39-49-C3-E6">[poster]</a></p>
    </div>
</body>

</html>

